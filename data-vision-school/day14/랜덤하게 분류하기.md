# 분류

## 기초 흐름
먼저 몇 퍼센트로 할지 정해준다  
0.9   <--- 이 수를 곱하게 되면 90%를 의미하게 되고  
이것을 슬라이싱을 이용해서 데이터를 가지고 오면 된다  
[0: len리스트 길이 * 0.9 ] ---> 처음부터 리스트길이의 90%까지 슬라이싱으로 가져오게 됨  
반대로   
[ len리스트 길이 * 0.9 : ] ---> 10%만 슬라이싱이 됨  

예제..
```py
my_nlist = np.arange(9)
SPLIT_RATIO = 0.9

my_nlist
#결과 array([0, 1, 2, 3, 4, 5, 6, 7, 8])

# 전체 길이에서 SPLIT_RATIO(0.9)를 곱하면 90%가 된다
my_nlist[ 0: int(len(my_nlist) * SPLIT_RATIO ) ]
# 결과 array([0, 1, 2, 3, 4, 5, 6, 7])

my_nlist[ int(len(my_nlist) * SPLIT_RATIO ) : ]
# 결과 array([8])
```

## 함수로 만들어서 자동 분류하기
함수정의  
```py
def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):

  # 사이즈
  # os.path.getsize( SOURCE)
  # 리스트로 보기
  # os.listdir(SOURCE)
  
  # 랜덤 리스트
  random_list = random.sample(os.listdir(SOURCE) , len(os.listdir(SOURCE) ))
  
  split = (len(random_list) * SPLIT_SIZE )
  train_image = random_list[ 0 : int(split) ] #90
  test_image = random_list[int(split): ] #10
  
  for one_image in test_image:
    if os.path.getsize( SOURCE + one_image ) > 0 :
      copyfile(SOURCE + one_image, TESTING + one_image)
    else:
      print('파일이 없거나, 복사가 완료')

  for one_image in train_image:
    if os.path.getsize( SOURCE + one_image ) > 0 :
      copyfile(SOURCE + one_image, TRAINING + one_image)
    else:
      print('파일이 없습니다')
```

디렉토리 저장 및 함수호출  
```py
CAT_SOURCE_DIR = "/tmp/PetImages/Cat/"
TRAINING_CATS_DIR = "/tmp/cats-v-dogs/training/cats/"
TESTING_CATS_DIR = "/tmp/cats-v-dogs/testing/cats/"
DOG_SOURCE_DIR = "/tmp/PetImages/Dog/"
TRAINING_DOGS_DIR = "/tmp/cats-v-dogs/training/dogs/"
TESTING_DOGS_DIR = "/tmp/cats-v-dogs/testing/dogs/"

split_size = .9
split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)
split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)
```

## train/test셋 복사 확인하기
```py
print(len(os.listdir('/tmp/cats-v-dogs/training/cats/')))
print(len(os.listdir('/tmp/cats-v-dogs/training/dogs/')))
print(len(os.listdir('/tmp/cats-v-dogs/testing/cats/')))
print(len(os.listdir('/tmp/cats-v-dogs/testing/dogs/')))
```

## 이후는 Convolution 학습시키기
### 임포트
```py
from keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.optimizers import RMSprop
```

### 모델링 (컨볼루션 맥스풀링)
```py
model = tf.keras.models.Sequential([
  Conv2D(filters= 16, kernel_size=(3,3), activation='relu', input_shape=(150, 150, 3) ),
  MaxPooling2D(2, 2),
  Conv2D(filters= 32, kernel_size=(3,3), activation='relu' ),
  MaxPooling2D(2, 2),
  Conv2D(filters= 64, kernel_size=(3,3), activation='relu' ),
  MaxPooling2D(2, 2),
  # DNN 하기
  Flatten(),
  Dense(units=512, activation='relu'),
  Dense(units=1, activation='sigmoid') 
])

model.compile(optimizer=RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])
```

### 이미지 제너레이터
트레이닝셋과 validation셋이 있으므로 제너레이터 2번씩 해준다  
```py
from tensorflow.keras.preprocessing.image import ImageDataGenerator


TRAINING_DIR = '/tmp/cats-v-dogs/training'
train_datagen = ImageDataGenerator( rescale=1 / 255.0)
# 제너레이터의 배치 사이즈는 꼭 10으로 하세요. (성능이 안 좋을 때 10씩, 한번에 10씩 메모리에 올림, 성능 좋은 컴퓨터는 더해도 된다고함)
train_generator = train_datagen.flow_from_directory( 
    TRAINING_DIR, batch_size = 10, target_size= (150, 150), class_mode='binary'
    )
# class_mode =binary는 2개로 분류하는 문제

VALIDATION_DIR = '/tmp/cats-v-dogs/testing'
validation_datagen  = ImageDataGenerator( rescale= 1 / 255.0)
validation_generator = validation_datagen.flow_from_directory( 
    VALIDATION_DIR, batch_size = 10, target_size= (150, 150), class_mode='binary'
    )
```

### 학습 및 변수에 저장
```py
history = model.fit(train_generator, epochs=15, verbose=1, validation_data=validation_generator)
```


## LOSS 와 ACCURACY 에 대한 차트를 그린다.
아래 코드는 복사 붙여넣기로 사용  
```py
# LOSS 와 ACCURACY 에 대한 차트를 그린다. 그냥 실행하시오!
%matplotlib inline

import matplotlib.image  as mpimg
import matplotlib.pyplot as plt

#-----------------------------------------------------------
# Retrieve a list of list results on training and test data
# sets for each training epoch
#-----------------------------------------------------------
acc=history.history['accuracy']
val_acc=history.history['val_accuracy']
loss=history.history['loss']
val_loss=history.history['val_loss']

epochs=range(len(acc)) # Get number of epochs

#------------------------------------------------
# Plot training and validation accuracy per epoch
#------------------------------------------------
plt.plot(epochs, acc, 'r', "Training Accuracy")
plt.plot(epochs, val_acc, 'b', "Validation Accuracy")
plt.title('Training and validation accuracy')
plt.figure()

#------------------------------------------------
# Plot training and validation loss per epoch
#------------------------------------------------
plt.plot(epochs, loss, 'r', "Training Loss")
plt.plot(epochs, val_loss, 'b', "Validation Loss")


plt.title('Training and validation loss')

```

