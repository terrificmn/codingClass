{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics from Stock Data\n",
    "\n",
    "구글, 애플, 아마존의 주식을 분석할 것입니다. 구글은 GOOG.csv 애플은 AAPL.csv 아마존은 AMZN.csv 파일에 주식 정보가 있습니다.\n",
    "\n",
    "다음 7개의 컬럼이 있습니다\n",
    "\n",
    "**Date Open High Low Close Adj_Close Volume**\n",
    "\n",
    "csv 파일을 읽어서 DataFrame 으로 처리할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 판다스를 임포트 하세요.\n",
    "import pandas as pd \n",
    "\n",
    "# GOOG.csv 파일을 판다스로 읽어서 저장하세요.\n",
    "\n",
    "\n",
    "\n",
    "# 데이터의 처음 5줄을 화면에 출력하세요.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# To Do\n",
    "\n",
    "우리는, 각 date 에 해당되는 adj close 값만 관심이 있습니다. 따라서 컬럼은 두개만 사용하며, 이 두개 컬럼의 인덱스는 date로 만듭니다. \n",
    "\n",
    "hints:\n",
    "\n",
    "* Use the `index_col` keyword to indicate which column you want to use as an index. For example `index_col = ['Open']`\n",
    "\n",
    "* Set the `parse_dates` keyword equal to `True` to convert the Dates into real dates of the form year/month/day\n",
    "\n",
    "* Use the `usecols` keyword to select which columns you want to load into the DataFrame. For example `usecols = ['Open', 'High']`\n",
    "\n",
    "Fill in the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the Google stock data into a DataFrame\n",
    "google_stock = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the Apple stock data into a DataFrame\n",
    "apple_stock =   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the Amazon stock data into a DataFrame\n",
    "amazon_stock = \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 6개까지 출력해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2000-01-01`  부터  `2016-12-31`년 까지의 데이터를 처리할것인데  `pd.date_range()` 함수를 이용해서 dates 변수를 만드세요. 그리고 나서 위의  dates 를 인덱스로 하여, 새로 all_stocks 란 데이터프레임을 만드세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create calendar dates between '2000-01-01' and  '2016-12-31'\n",
    "dates = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create and empty DataFrame that uses the above dates as indices\n",
    "all_stocks =   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "각 `google_stock`, `apple_stock`, `amazon_stock`, 을,  `all_stocks` 의 날짜에 매칭하여 수정종가를 나오게 하기 위해, all_stocks와 각각의 데이터프레임을 join 할 것입니다. 그러나 일단은 먼저, 현재의 구글,애플, 아마존의 DataFrame에 있는 컬럼명을, 각각의 수정종가로 표현하기 위해, 각각의 adj close 를 google_stock, apple_stock, amazon_stock 로 바꿔주세요.  `pd.DataFrame.rename()` 함수를 이용하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the Adj Close column label to Google\n",
    "google_stock =  \n",
    "\n",
    "# Change the Adj Close column label to Apple\n",
    "apple_stock =   \n",
    "\n",
    "# Change the Adj Close column label to Amazon\n",
    "amazon_stock =   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We display the google_stock DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We display the apple_stock DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We display the amazon_stock DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 `all_stocks` DataFrame 를 기준으로, 각각의 구글,애플,아마존의 데이터프레임을 합치겠습니다. `dataframe.join()` 함수를 이용하세요. T `dataframe1.join(dataframe2)`  `dataframe1` 을 기준으로 `dataframe2`를 합치는 함수입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We join the Google stock to all_stocks\n",
    "all_stocks =  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We join the Apple stock to all_stocks\n",
    "all_stocks =  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We join the Amazon stock to all_stocks\n",
    "all_stocks =   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `all_stocks`  를 앞에서 10줄 출력하여 확인하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "해당 년도의 데이터가 없는 경우도 있을것입니다. 즉, 데이터가 NaN 으로 나오면 해당년도 데이터가 없는것입니다. 그러므로 NaN이 포함되어 있는지 먼저 확인해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are any NaN values in the all_stocks dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 NaN 값을 포함하는 행은 제거합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any rows that contain NaN values\n",
    "all_stocks =   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `all_stocks`  에 NaN 이 없어졌는지 체크해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are any NaN values in the all_stocks dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `all_stocks`  를 화면에 출력하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We display the all_stocks DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 아래의 통계데이터를 얻어봅시다. 아래를 각각 채워서 실행해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 스톡의 평균을 출력하세요\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# 각 스톡의 표준편차를 출력하세요.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 스톡의 correlation을 출력하세요. 상관관계\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
