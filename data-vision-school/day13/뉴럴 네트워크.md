# 뉴럴 네트워크
[참고: 텐서플로우.org](https://www.tensorflow.org/guide)

## 데이터 가공
- 문자열 바꾸기:  
2개 또는 3개 이상으로 반복되는 **Categorical data** (문자열)이 있을 때 학습을 시키기 위해서는 반드시 숫자로 변환해 줘야함  
`dataframe.unique()`로 확인 가능

### Label Encoding 레이블 인코딩  
- 패키지 모듈 불러오기
```py
from sklearn.preprocessing import LabelEncoder
```

- LabelEncoder 사용  
X['Gender']가 Male, Female의 2개의 카테고리컬 데이터 반복일 때  

```py
#먼저 생성
labelEncoder_gender = LabelEncoder()
# 객체에서 fit_transform() 후 저장해주기
X['Gender'] = labelEncoder_gender.fit_transform(X ['Gender'])
```

### One Hot Encoding 원 핫 인코딩
- 패키지/모듈 불러오기  
```py
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
```

- ColumnTransformer 생성  
ColumnTransformer를 생성할 때 OneHotEncoder()로 변환  
만약 array(['France', 'Spain', 'Germany'], dtype=object) 이런 단어가 반복되어 쓰이고 있다면 원핫인코딩을 하면   

|3개 컬럼 추가됨-->|France | Spain| Germany| 
|:--|:--:|:--:|:--:|
| France | 1 | 0 | 0 |
| Spain | 0 | 0 | 1 |
| Germany | 0 | 1 | 0 |  

컬럼이 3개로 늘어나면서 알파벳 순서대로 1 이 들어가고 나머지는 0으로 됨

```py
ct = ColumnTransformer( [ ( 'encoder', OneHotEncoder(), [인덱스] ) ], remainder='passthrough' )
# 인덱스에는 컬럼의 컴퓨터용 인덱스를 넣어준다
```

- 변환
```py
# numpy array로 만든다
X = np.array( ct.fit_transform(X), dtype=np.float)
# dtype=np.float는 생략 가능
```

- Dummy Variable Trap 더미 트랩을 제거    
`One Hot Encoding`을 한 후 맨 왼쪽 컬럼을 지워도 분류하는데 구별하는데는 문제가 없어서, 가장 왼쪽 하나의 컬럼은 지워도 된다.   
지우는 방법은 *ndarray* 데이터 액세스 하는 방식으로 한다  
```py
# [ row , col ] 슬라이싱으로 1번 (0번 빼고) 다 
X = X[ : , 1: ]
```

## Feature Scaling
둘 중 선택  
- StandardScaler  
``` py
from sklearn.preprocessing import StandardScaler

sc = StandardScaler()
# X의 값이 편차가 크기 때문에 피쳐스 스케일링을 해줘야 한다
X_scaled = sc.fit_transform(X)
```

- MinMaxScaler
```py
from sklearn.preprocessing import MinMaxScaler

mm = MinMaxScaler()
X_mm_scaled = mm.fit_transform(X)
```

## 트레인 / 테스트 나누기
```py
#패키지 모듈
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=0)
```

## 텐서플로우 학습 
여태껏 머신러닝은 알고리즘으로 (문제를 해결하기 위한 순서와 방법) 해결한 것이었으나
딥러닝은 알고리즘으로 돌아가는 것이 아니고, 인공 신경망을 이용해서 수학식(방정식), 액티베이션 함수으로 
돌아가는 것  

여기서 수학식은 *Linear Regression* 에서 사용한 식 처럼  
`y = ax1 + bx2 + cx3 + e` ( x는 컬럼의 값들이 들어가짐) 
이 처럼 이 공식이 뉴런에 왼쪽의 공식에 들어가짐

(컬럼이 11개로 가정) 11개 컬럼이 되어서 (*One Hot Encoding*으로)
처음 Input Layer의 뉴런이 11개가 되는 것 (컬럼 수가 결정)

ax1 + bx2 + cx3 + dx4 .... kx11 + q
컴퓨터는 여기에서는 a, b, c...부터  k 까지의 값을 찾는 것 (처음에는 랜덤으로 함)  
인공신경망 그림에서는 선 들을 의미한다 == w 라고 하고 == weight == 가중치 라고 함

- 모듈 불러오기
```py
import tensorflow as tf
import numpy as np
import pandas as pd
from keras.models import Sequential
from keras.layers import Dense
```

- 인공지능 생성
```py
model = Sequential()
```
- Dense 추가 (레이어를 의미)  
```py
model.add( Dense( input_dim = 11, units = 6, activation='relu') )

# 추가 시키려면 add()로 계속 추가 가능. 하이퍼 파라미터 개념
model.add( Dense( units= 8, activation=tf.nn.relu) )
```
add() 메서드를 사용해서 Dense()를 추가  
Dense() args는 `input_dim = 11` 컬럼 수와 동일하게 셋팅  
`activation='relu'` 함수는 relu로 지정  
`units = 6` 뉴런의 갯수를 의미  
액티베이션 함수 중 `tf.nn.sigmoid` / `tf.nn.relu` 그냥 함수 이름만 써줘도 같다. 예: activation=relu

- 마지막 output layer   
마지막 `units=` 는 1이 된다
```py
model.add( Dense( units=1, activation=tf.nn.sigmoid) ) 
```

- 컴파일 설정  
loss= (오차함수) 오차 계산하는 방식 'binary_crossentropy'  - 0과 1로 분류하는 문제     
optimizer='adam' 잘 모르겠으면 adam 함수,   
참고로: sgd 도 있었음 Stochastic Gradient Descent  

```py
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'] )
```

### Vanishing Gradient 현상
Activation Functions를 Sigmoid, Tanh를 hidden layer에서 정해놓으면  
오차가 0이 되면 학습이 완벽하기 때문에 끝이 나는데,  
만약 Sigmoid, Tanh가 0이 되어 버려도 오차계산이 다 안 끝났는데 계산이 끝나버리면서 오히려 오차가 생겨버리는 현상   
그래서 Sigmoid, Tanh 함수는 히든레이어에서는 사용하지 않는다

## fit 학습
```py
model.fit(X_train, y_train, epochs=20, batch_size=10)
```

### 용어 정리
*epochs* --> 한 번의 epoch는 신경망에서 전체 데이터 셋에 대해 forward pass/backward pass 과정을 거친 것을 말함. 즉, 전체 데이터 셋에 대해 한 번 학습을 완료한 상태  
한정된 데이터를 가지고 다시 입력을 다시 해서 가중치를 계속바꿀 수 있으므로 다시 반복해서 학습하게 하는 것 (오차가 줄어듬)  

*batch_size* ---> 메모리의 한계와 속도 저하 때문에 대부분의 경우에는 한 번의 epoch에서 모든 데이터를 한꺼번에 집어넣을 수는 없습니다. 그래서 데이터를 나누어서 주게 되는데 이때 몇 번 나누어서 주는가를 iteration, 각 iteration마다 주는 데이터 사이즈를 batch size라고 합니다.  
행렬로 한꺼번에 대입해서 전체 데이터셋 중 일부를 나눠서 한번에 학습하게 하는 것

- loss / accuracy  
화면 verbose로 보여지는 부분에서 
loss는 학습하면 생긴 오차 (binary_crossent ropy 함수를 이용) 낮을 수록 좋다  
accuracy 정확도는 (compusion matrix로 계산) 높을 수록 좋음

## 예측
```py
y_pred = model.predict(X_test)
```
Output Layer의 액티베이션 함수를 시그모이드를 사용했기 때문에 0과 1만 (사이의 값) 나오게 됨. 이는 분류를 할 때 사용할 수 있다  
`y_pred.min()` 또는 `y_pred.max()`를 해보면 결과가 0.002 ~ 0.99 이런식으로 나오게 됨

- 예측값 0.5 보다 크면?
true로 보면 된다
```py
y_pred > 0.5
```

- 예측값을 0과 1로 딱 떨어지게 하는 방법
```py
# 위의 코드를 사용하자
y_pred = model.predict_classes(X_test)
``` 
하지만 위의 방법은 deprecated 됨. warning 메세지가 뜸, 사용은 아직 가능

>Please use instead: `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification (e.g. if it uses a `softmax` last-layer activation).

3개이상의 분류 문제 일때, 참고: 그래서 2개의 분류 문제일 때는 제대로 된 값 변환이 안됨

>`(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification (e.g. if it uses a `sigmoid` last-layer activation).

0과 1로 분류하는 2개의 분류 문제 일 때는 사용


## 컨퓨전 매트릭스, accuracy_score
- 묘듈
```py
from sklearn.metrics import confunsion_matrix, accuracy_score
```

- 정확도 계산
```py
cm = confusion_matrix(y_test, y_pred)

# output
# [[1525,   70],
# [ 207,  198]]

(1525 + 198) / cm.sum()
```

- accuracy_score 사용  
자동으로 계산 해줌
```py
accuracy_score(y_test, y_pred)
```

### loss and Accuracy 오차와 정확
loss value와 accuracy value를 리턴함, 변수 2개 필요 
```py
test_loss, test_acc = model.evaluate(X_test, y_test)
```

## 신규 데이터 예측 분류
- Geography: France
- Credit Score: 600
- Gender: Male
- Age: 40
- Tenure: 3
- Balance: 60000
- Number of Products: 2
- Has Credit Card: Yes
- Is Active Member: Yes
- Estimated Salary: 50000  


먼저 데이터가 row 에 들어가 있다고 가정하면 
[600, 'France', 1 , 40, 3, 60000, 2, 1, 1, 50000]  

여기에서 One Hot Encoding을 한다 (가정). 변환된 것이 컬럼의 맨앞으로 오면서 country 컬럼이 3개가 됨  
[ 0, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]

그리고 Dummy Variable Trap 를 제거 맨 처음 컬럼 삭제
[ 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]
이렇게 해서 numpy array로 만들어 준다

```py
X1 = np.array([ 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000])
```

- 피쳐 스케일링  
학습 데이터가 했던 피처 스케일링을 같이 해줘야한다
X1을 sc 또는 mm 객체로 transform()해주면 되는데 에러가 남

에러 처리도 똑똑하네;; ㅋ
>Expected 2D array, got 1D array instead:
Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1)

위의 메세지 처럼 해주면 됨
```py
X1 = X1.reshape(1, -1)
# StandardScaler사용
X1_scaled = sc.transform(X1)
```
- 그리고 예측
```py
y_pred_X1 = model.predict(X1_scaled)

# 분류의 문제일 시
y_pred_X1 > 0.5

#output
True or False
```


# 정리 따로 저장하는게 ㄴ
___
학습 model.fit 할 때 변수에 저장해주면

epochs_hist.history 
속성으로 히스토리 볼 수 있음
딕셔너리 형태로 되어 있는데  키들 중 'loss'를 사용해서 
차트를 그릴 수 있음

```py
plt.plot(epochs_hist.history['loss'])
plt.title('Loss Progression during Training')
plt.xlabel('Epoch Number')
plt.ylabel('Training Loss')
plt.show()
```

epochs는 어느정도 도달하면 오차는 더 이상 줄어들지 않음  
epochs를 많이 하더라도 학습 성능이 좋아지는 것은 아님!  
epochs 를 몇 번 하는 것이 효과적인지 알 수 있다  


y_pred 예측값 데이터 프레임 만들기
```py
#ret_df = pd.DataFrame( {'실제값': y_test.reshape(-1, ), '예측값': y_pred.reshape(-1, ) } )
```

'''py
# plt.figure(figsize=(10,8))
# plt.plot(ret_df['실제값'],'g-')
# plt.plot(ret_df['예측값'],'b-')
# plt.show()
```