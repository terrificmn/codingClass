예전에는 회사에서 서버를 구성하고   
웹서버 한 대, DB서버 한 대    
이런식으로 사용을 하는데    
트래픽이 증가하면 서버 증설을 하고 트래픽을 분산해주는 load balancer 도 설치해주고   
데이터베이스도 꽉 차면 또 DB서버도 증설하고    
이런식으로 했었다고 한다

시스템 엔지니어 등이 설치하고 있었으나 ..

Scale UP 서버 사양을 올리는 것 (예를 들어 cpu를 16코어로 업그레이드)   
Scale out  서버를 병렬적으로 늘리는 것


근데 이제 클라우드 서비스에서 자동적으로 다 해주는 방식으로 바뀌어서 사용하고 있다

대표적으로 AWS가 있는데 

여기에서는 서버 증설 EC2를 늘리는 것도 마우스 클릭으로만 하면 되고    
Elastic Load Balancing 도 마우스 클릭만 하면 되고,    
데이터 베이스 RDS도 더 쉽게 할 수 있게 클라우드에서 제공해주게 되었다.

기존 회사에서 하던 것들을 클라우드에서 할 수 있게 된 것임   

이제 서버 없이도 할 수 있게 되는 서비스들이 나오게 되는데   
ssh로 접속할 필요도 없고, centos / ubuntu등을 설치할 필요도 없다고 한다.   
이것이 바로 서버리스 인데 

대표적으로 AWS의 람다와 API Gateway가 있다고 한다   

API Gateway를 통해서 Lambda 가 실행이 되면서 RDS(db)를 할 수 있게 한다고 함   

프리티어는    
API Gateway 월 1백만건까지 무료   
람다도 월 1백만건 무료   




로컬에 있는 소스코드를 서버리스에 어떻게 옮길 것 인가?   

먼저 Git hub에 리포지터리를 생성해서 push를 해서 올린다   

AWS클라우드에서 설정을 하면 git hub에서 자동으로 가져온다

API Gateway에서 자동으로 경로를 설정하고    
람다에 자동으로 배포가 된다    
서버는 RDS를 사용하게 된다   

이제 접속은 (테스트, 일반사용자 모두 ) API Gateway에의 endpoint로 접속을 하게 된다   
트래픽이 증가하면 람다에서 알아서 서버 scaling out, up등을 알아서 처리하게 된다   

소스코드를 수정했다면 깃허브에 올리면 또 이제    
AWS API Gateway에서 자동으로 다운을 받아서 또 자동으로 하게 되는 것이라고 한다

